# scripts/fetch_weather_data.py
import requests
import pandas as pd
import os
from datetime import datetime, timedelta
import time
import subprocess
import sys

# Major cities with their coordinates
CITIES = {
    'New York': {'lat': 40.7128, 'lon': -74.0060, 'timezone': 'America/New_York'},
    'London': {'lat': 51.5074, 'lon': -0.1278, 'timezone': 'Europe/London'},
    'Tokyo': {'lat': 35.6762, 'lon': 139.6503, 'timezone': 'Asia/Tokyo'},
    'Sydney': {'lat': -33.8688, 'lon': 151.2093, 'timezone': 'Australia/Sydney'},
    'Paris': {'lat': 48.8566, 'lon': 2.3522, 'timezone': 'Europe/Paris'},
    'Mumbai': {'lat': 19.0760, 'lon': 72.8777, 'timezone': 'Asia/Kolkata'},
    'Beijing': {'lat': 39.9042, 'lon': 116.4074, 'timezone': 'Asia/Shanghai'},
    'São Paulo': {'lat': -23.5558, 'lon': -46.6396, 'timezone': 'America/Sao_Paulo'},
    'Cairo': {'lat': 30.0444, 'lon': 31.2357, 'timezone': 'Africa/Cairo'},
    'Moscow': {'lat': 55.7558, 'lon': 37.6173, 'timezone': 'Europe/Moscow'},
    'Los Angeles': {'lat': 34.0522, 'lon': -118.2437, 'timezone': 'America/Los_Angeles'},
    'Dubai': {'lat': 25.2048, 'lon': 55.2708, 'timezone': 'Asia/Dubai'},
    'Singapore': {'lat': 1.3521, 'lon': 103.8198, 'timezone': 'Asia/Singapore'},
    'Berlin': {'lat': 52.5200, 'lon': 13.4050, 'timezone': 'Europe/Berlin'},
    'Toronto': {'lat': 43.6532, 'lon': -79.3832, 'timezone': 'America/Toronto'},
    'Mexico City': {'lat': 19.4326, 'lon': -99.1332, 'timezone': 'America/Mexico_City'},
    'Buenos Aires': {'lat': -34.6118, 'lon': -58.3960, 'timezone': 'America/Argentina/Buenos_Aires'},
    'Lagos': {'lat': 6.5244, 'lon': 3.3792, 'timezone': 'Africa/Lagos'},
    'Istanbul': {'lat': 41.0082, 'lon': 28.9784, 'timezone': 'Europe/Istanbul'},
    'Bangkok': {'lat': 13.7563, 'lon': 100.5018, 'timezone': 'Asia/Bangkok'},
}

def fetch_weather_data(city_name, city_info):
    """Fetch weather data for a specific city from Open-Meteo API"""
    # Get data for the last 7 days
    end_date = datetime.now().date()
    start_date = end_date - timedelta(days=7)
    
    url = "https://api.open-meteo.com/v1/forecast"
    params = {
        'latitude': city_info['lat'],
        'longitude': city_info['lon'],
        'daily': [
            'temperature_2m_max',
            'temperature_2m_min',
            'temperature_2m_mean',
            'precipitation_sum',
            'windspeed_10m_max',
            'windgusts_10m_max',
            'winddirection_10m_dominant',
            'sunshine_duration',
            'precipitation_probability_max',
            'uv_index_max'
        ],
        'timezone': city_info['timezone'],
        'start_date': start_date.strftime('%Y-%m-%d'),
        'end_date': end_date.strftime('%Y-%m-%d'),
        'past_days': 7
    }
    
    try:
        response = requests.get(url, params=params, timeout=30)
        response.raise_for_status()
        return response.json()
    except requests.RequestException as e:
        print(f"Error fetching data for {city_name}: {e}")
        return None

def process_weather_data(weather_data, city_name):
    """Process weather data into a structured format"""
    if not weather_data or 'daily' not in weather_data:
        return []
    
    daily_data = weather_data['daily']
    dates = daily_data['time']
    
    records = []
    for i, date in enumerate(dates):
        record = {
            'date': date,
            'city': city_name,
            'country': get_country_from_city(city_name),
            'latitude': weather_data.get('latitude', 0),
            'longitude': weather_data.get('longitude', 0),
            'timezone': weather_data.get('timezone', ''),
            'temperature_max_c': daily_data.get('temperature_2m_max', [None])[i],
            'temperature_min_c': daily_data.get('temperature_2m_min', [None])[i],
            'temperature_mean_c': daily_data.get('temperature_2m_mean', [None])[i],
            'precipitation_mm': daily_data.get('precipitation_sum', [None])[i],
            'windspeed_max_kmh': daily_data.get('windspeed_10m_max', [None])[i],
            'windgust_max_kmh': daily_data.get('windgusts_10m_max', [None])[i],
            'wind_direction_degrees': daily_data.get('winddirection_10m_dominant', [None])[i],
            'sunshine_duration_hours': daily_data.get('sunshine_duration', [None])[i],
            'precipitation_probability_max': daily_data.get('precipitation_probability_max', [None])[i],
            'uv_index_max': daily_data.get('uv_index_max', [None])[i],
            'data_fetched_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # Convert sunshine duration from seconds to hours
        if record['sunshine_duration_hours'] is not None:
            record['sunshine_duration_hours'] = round(record['sunshine_duration_hours'] / 3600, 2)
        
        records.append(record)
    
    return records

def get_country_from_city(city_name):
    """Map city names to countries"""
    country_mapping = {
        'New York': 'United States',
        'Los Angeles': 'United States',
        'London': 'United Kingdom',
        'Tokyo': 'Japan',
        'Sydney': 'Australia',
        'Paris': 'France',
        'Mumbai': 'India',
        'Beijing': 'China',
        'São Paulo': 'Brazil',
        'Cairo': 'Egypt',
        'Moscow': 'Russia',
        'Dubai': 'United Arab Emirates',
        'Singapore': 'Singapore',
        'Berlin': 'Germany',
        'Toronto': 'Canada',
        'Mexico City': 'Mexico',
        'Buenos Aires': 'Argentina',
        'Lagos': 'Nigeria',
        'Istanbul': 'Turkey',
        'Bangkok': 'Thailand',
    }
    return country_mapping.get(city_name, 'Unknown')

def upload_to_kaggle(csv_file_path, dataset_slug):
    """Upload the CSV file to Kaggle dataset"""
    try:
        # Create dataset metadata
        metadata = {
            "title": "Global Weather Dataset - Daily",
            "id": f"{os.environ.get('KAGGLE_USERNAME')}/{dataset_slug}",
            "licenses": [{"name": "CC0-1.0"}],
            "resources": [{
                "path": csv_file_path,
                "description": "Daily weather data for major cities worldwide, updated automatically"
            }]
        }
        
        # Create dataset-metadata.json
        import json
        with open('dataset-metadata.json', 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # Upload to Kaggle
        print("Uploading to Kaggle...")
        result = subprocess.run([
            'kaggle', 'datasets', 'version', 
            '-p', '.', 
            '-m', f'Automated update - {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}'
        ], capture_output=True, text=True)
        
        if result.returncode == 0:
            print("Successfully uploaded to Kaggle!")
            print(result.stdout)
        else:
            print(f"Error uploading to Kaggle: {result.stderr}")
            # Try creating new dataset if version update fails
            print("Attempting to create new dataset...")
            create_result = subprocess.run([
                'kaggle', 'datasets', 'create', 
                '-p', '.', 
                '--dir-mode', 'zip'
            ], capture_output=True, text=True)
            
            if create_result.returncode == 0:
                print("Successfully created new dataset on Kaggle!")
                print(create_result.stdout)
            else:
                print(f"Error creating dataset: {create_result.stderr}")
                
    except Exception as e:
        print(f"Error uploading to Kaggle: {e}")

def main():
    """Main function to fetch weather data and upload to Kaggle"""
    print("Starting weather data collection...")
    
    all_records = []
    
    for city_name, city_info in CITIES.items():
        print(f"Fetching weather data for {city_name}...")
        weather_data = fetch_weather_data(city_name, city_info)
        
        if weather_data:
            records = process_weather_data(weather_data, city_name)
            all_records.extend(records)
            print(f"Successfully processed {len(records)} records for {city_name}")
        else:
            print(f"Failed to fetch data for {city_name}")
        
        # Add delay to be respectful to the API
        time.sleep(1)
    
    if all_records:
        # Create DataFrame and save to CSV
        df = pd.DataFrame(all_records)
        
        # Sort by date and city
        df = df.sort_values(['date', 'city'])
        
        # Save to CSV
        csv_filename = 'weather_daily.csv'
        df.to_csv(csv_filename, index=False)
        
        print(f"Successfully created {csv_filename} with {len(df)} records")
        print(f"Date range: {df['date'].min()} to {df['date'].max()}")
        print(f"Cities included: {df['city'].nunique()}")
        
        # Upload to Kaggle
        upload_to_kaggle(csv_filename, 'global-weather-dataset-daily')
        
    else:
        print("No weather data collected!")
        sys.exit(1)

if __name__ == "__main__":
    main()
